---
title: "NYPD Shooting Incident Data"
output:
  html_document:
    df_print: paged
  word_document: default
  pdf_document: default
date: "2024-12-12"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r map package installation, eval=FALSE, include=FALSE}
# Installing the package leaflet; this allows interactions with the map:
install.packages("leaflet")
```

```{r reshape2 package installation, eval=FALSE, include=FALSE, warning=FALSE}
install.packages("reshape2")
```

```{r importing the map, include=FALSE}
# Importing leaflet from the library:
library(leaflet)
```

```{r importing tidyverse, eval=TRUE, include=FALSE, warning=FALSE}
# Importing the required libraries:
library(tidyverse)
library(dplyr)
library(tidyr)
library(ggplot2)
library(reshape2)
```

## Project Description

List of every shooting incident that occurred in NYC going back to 2006 through the end of the previous calendar year.

This is a breakdown of every shooting incident that occurred in NYC going back to 2006 through the end of the previous calendar year. This data is manually extracted every quarter and reviewed by the Office of Management Analysis and Planning before being posted on the NYPD website. Each record represents a shooting incident in NYC and includes information about the event, the location and time of occurrence. In addition, information related to suspect and victim demographics is also included.

## Objectives

My aim in this analysis is to understand the data pattern and trend from the sample at hand, in order to capture some information on crime, related to human behavior, geography and demography.

I will also create a prediction model that predicts the classsification of the shooting, whether it is flagged as a murder or not.

## Data Overview

This section shows the original data, what does it cover, its characteristics and what are the biases.

Let's have a look:

```{r original data, include=TRUE}
# Importing the dataframe from https://data.cityofnewyork.us website, and showing it:
original_df <- readr::read_csv("https://data.cityofnewyork.us/api/views/833y-fsy8/rows.csv?accessType=DOWNLOAD", show_col_types = FALSE)
original_df
```

The data has a lot of null and NA values specifically in the location, perp age group, perp sex and perp race. The reason that the perp information show a lot of NA values might be because of the fact that the perp has not been captured or no eye witness or cameras that could describe or show the perp. In addition, sometimes cases don't have much information on where the crime happened such as location, and this is what we also see in this dataset.


- **Bias Analysis**:

As mentioned before, the original dataset contains a lot of na and null values, which makes the dataset imbalanced, and one of the indicators for bias in data is the imbalance in the features, in which it results in inaccurate machine learning models and inaccurate data analysis.


## Data Analysis

I want to analyse the data from the 3 main aspects:

- Occurrence time
- Location/Boro
- Sex distribution of perpetrators and victims
- Age range for perp and victim

#### Occurence time:
  
I am curious to know the time where most of the shooting happened, let's have a look:

```{r time analysis}
# Extracting from the OCCUR_TIME column the hours:
updated_df <- original_df %>%
  separate(OCCUR_TIME, into = c("OCCUR_HOUR", "OCCUR_MIN", "OCCUR_SEC"), sep = "\\:") %>%
  select(-c("OCCUR_MIN", "OCCUR_SEC"))

# Grouping on the occurence time and counting the number of occurences:
shootings_count_df <- updated_df %>%
  select(c("OCCUR_HOUR"), sort("OCCUR_HOUR", decreasing = FALSE)) %>%
  group_by(OCCUR_HOUR) %>%
  count(OCCUR_HOUR) %>%
  rename(COUNT_SHOOTINGS = n)
shootings_count_df
```

Let's visualize this:

```{r Visualizing the counts of shootings as per the OCCUR_HOUR, fig.width=15, fig.height=8}
# Converting OCCUR_HOUR to a factor to maintain the order in the barplot:
shootings_count_df$OCCUR_HOUR <- factor(shootings_count_df$OCCUR_HOUR, levels = shootings_count_df$OCCUR_HOUR)

# Changing the font size:
par(cex = 1.5)

# Creating the barplot:
barplot(
  height = shootings_count_df$COUNT_SHOOTINGS,
  names.arg = shootings_count_df$OCCUR_HOUR,
  col = "blue",
  main = "Shootings stats by Hour",
  xlab = "Hour",
  ylab = "Count of Shootings",
  las = 2, # Rotate x-axis labels
  cex.names = 1, # Font size of x-axis names
  cex.lab = 1.6  # Font size for y-axis label
)
```


From the barplot above, we can see that the shootings are at peak during midnight and go lower as the time passes until between 7 and 9 AM, where the rate is at its lowest. From 9 AM onward, the shooting rate starts going exponentially higher as time passes.

#### Location/Boro

Let's see now the distribution of data in each boro per coordinate, in order to conclude where the most shootings happened. I will create a dataframe showing the count of shooting in each coordinate and visualize it. In the following dataframe, I am dropping the na values from Latitude and Longitude.

```{r location analysis}
location_boro_df <- original_df %>%
  select(c("BORO", "Latitude", "Longitude")) %>%
  drop_na(Latitude, Longitude) %>%
  reframe(BORO, Latitude, Longitude) %>%
  count(BORO, Latitude, Longitude) %>%
  rename(Number_of_Shootings = n)
location_boro_df
```

Now, I want to visualize the number of shootings per boro per coordinate on a map, so we can have better visibility on the distribution of data:

```{r visualizing on a map}
# Creating a color palette based on each BORO:
color_palette <- colorFactor(
  palette = c("red", "blue", "green", "yellow", "orange"),
  domain = location_boro_df$BORO
)

# Creating the leaflet map:
leaflet(location_boro_df) %>%
  addTiles() %>%
  addCircleMarkers(
    ~Longitude, ~Latitude,
    radius = ~sqrt(Number_of_Shootings) * 3, # Scaling the marker size
    color = ~color_palette(BORO), # Assigning color based on BORO
    fillOpacity = 0.7,
    popup = ~paste("Boro:", BORO, "<br>",
                   "Number of Shootings:", Number_of_Shootings)
  ) %>%
  setView(lng = mean(location_boro_df$Longitude), lat = mean(location_boro_df$Latitude), zoom = 12) %>%
  addLegend(
    "bottomright",
    pal = color_palette,
    values = ~BORO,
    title = "Borough",
    opacity = 1
  )
```


- **Analysis on the shooting location**

    - Staten Island: Looking at the concentration of the data points, we can conclude that the most shootings happened in the north. The distance between those data points in this part of Staten Island is not that short, so the shooting did not happen in every street; on the other hand it is noticed that the parks were quite peaceful.
    
    - Brooklyn: The concentration of data points in Brooklyn are taking the majority of the borough, however, it is leaning more towards mid to north east. The data shows that these shootings were closed to each other, in which one can see that in almost every street a shooting happened.
    
    - Queens: In Queens we can see that the data points are clustered in both regions, north and south. The northern side data concentration is less than the southern side though. We can also notice that Inwood region has no shootings at all.
    
    - Manhattan: In Manhattan you can see the data concentrated in the north, south and west of the borough, where in the northern region the data points are more close to each other indicating the shootings happened in more areas. The data shows 2 points located in the Bronx area, but these are obviously outliers and too small to have an impact.
    
    - Bronx: The data points in the Brox are actually concentrated all ove the borough, with slightly less in the east.


#### Age Range for Perp and Victim

I want to look into the age range of the victim and perp, showing at the same time if the shooting ended up categorized as a murder. This will give an insight on the death count per age. Since the data contains a lot of missing information, either an NA or Null value, it would make sense to omitt all rows/records that contain missing data and consider the remaining data as a sample that should give me the insight I need.

I will also leave the perp and victim sex and race and see what the correlations are, if any.

```{r age range analysis}
# Removing the records with missing data and creating the required dataframe:
perp_victim_df <- original_df %>%
  na.omit() %>%
  filter(LOCATION_DESC != "(null)" &
          PERP_AGE_GROUP != "(null)" &
          PERP_SEX != "(null)" &
          PERP_RACE != "(null)") %>%
  select(-c("INCIDENT_KEY", "OCCUR_DATE", "OCCUR_TIME", "LOC_OF_OCCUR_DESC", "PRECINCT", "JURISDICTION_CODE", "LOC_CLASSFCTN_DESC", "LOCATION_DESC", "X_COORD_CD", "Y_COORD_CD", "Latitude", "Longitude", "Lon_Lat")) %>%
  relocate(STATISTICAL_MURDER_FLAG, .after = "VIC_RACE") %>%
  relocate(VIC_AGE_GROUP, .after = "PERP_AGE_GROUP")
perp_victim_df
```

#### Sex distribution of perpatrators and victims

Let's visualize the above dataframe and see what insights we have:

```{r visualizing per_victim_df}
ggplot(perp_victim_df, aes(x = PERP_SEX, fill = VIC_SEX)) +
  geom_bar(position = "dodge") +
  labs(title = "Sex Distribution: Perpetrators vs. Victims",
       x = "Perpetrator Sex", y = "Count") +
  theme_minimal()
```

- **Analysis on the sex distribution for perpetrators and victims**

  - The graph above shows clearly that:

    - The perpetrators are majority males.
  
    - The female and male victims of the female perpetrators are significantly less than the female and male victims of the male perpetrators.
  
    - The female victims in general are less than the male victims.


Next, I want to calculate the mean age of both the perp and victim, and see what is the difference between them. This might give me some insights on the relation between those 2 populations.

```{r mean calculation}
# Creating the mean age of perp list:
mean_age_perp <- c() # Initializing an empty list
for (i in perp_victim_df$PERP_AGE_GROUP){
  if (i == "<18") {
    mean_age_perp[[length(mean_age_perp) + 1]] = as.numeric(str_split(i, "<", simplify = TRUE))[2]/2  # Appending the list if the value is "<18"
  }
  else if (i == "65+") {
    mean_age_perp[[length(mean_age_perp) + 1]] = (as.numeric(str_split(i, "\\+", simplify = TRUE))[1] + 90)/2  # Appending the list if the value is "65+"
  }
  else {
    mean_age_perp[[length(mean_age_perp) + 1]] = (as.numeric(str_split(i, "-", simplify = TRUE))[1] + as.numeric(str_split(i, "-", simplify = TRUE))[2])/2  # Appending the list for all other values
  }
}

# Creating the mean age of victim list:
mean_age_victim = c()
for (i in perp_victim_df$VIC_AGE_GROUP){
  if (i == "<18") {
    mean_age_victim[[length(mean_age_victim) + 1]] = as.numeric(str_split(i, "<", simplify = TRUE))[2]/2  # Appending the list if the value is "<18"
  }
  else if (i == "65+") {
    mean_age_victim[[length(mean_age_victim) + 1]] = (as.numeric(str_split(i, "\\+", simplify = TRUE))[1] + 90)/2  # Appending the list if the value is "65+"
  }
  else {
    mean_age_victim[[length(mean_age_victim) + 1]] = (as.numeric(str_split(i, "-", simplify = TRUE))[1] + as.numeric(str_split(i, "-", simplify = TRUE))[2])/2  # Appending the list for all other values
  }
}

# Appending both lists to the dataframe:
perp_victim_df_updated <- perp_victim_df %>%
  add_column(MEAN_AGE_PERP = unlist(mean_age_perp), MEAN_AGE_VICTIM = unlist(mean_age_victim)) %>%
  relocate(MEAN_AGE_PERP, .before = "PERP_AGE_GROUP") %>%
  relocate(MEAN_AGE_VICTIM, .after = "MEAN_AGE_PERP")
perp_victim_df_updated
```

- **Bias Analysis**:

The sample above shows an overwhelmingly higher number of male perps than female, which is causing an imbalance, thus it will potentially impact any model we want to create from this data.

Let's have a look at the highest age mean for both perp and victim in each borough, in addition to the statistical murder flag:

```{r further age range analysis}
perp_victim_stats_df <- perp_victim_df_updated %>%
  select(c("BORO", "MEAN_AGE_PERP", "MEAN_AGE_VICTIM", "STATISTICAL_MURDER_FLAG", "PERP_SEX", "VIC_SEX", "PERP_RACE")) %>%
  group_by(BORO, PERP_SEX, PERP_RACE) %>%
  reframe(
    mean_age_perp = mean(MEAN_AGE_PERP),
    mean_age_vic = mean(MEAN_AGE_VICTIM)
  )
perp_victim_stats_df
```

Visualizing the the comparison of mean age between perps and victims in each borough:

```{r visualization between age means}
ggplot(perp_victim_stats_df, aes(x = mean_age_perp, y = mean_age_vic, color = PERP_RACE, shape = PERP_SEX)) +
  geom_point(size = 3) +
  facet_wrap(~BORO) +
  labs(title = "Mean Age of Perpetrators vs Victims",
       x = "Mean Age of Perpetrators", y = "Mean Age of Victims") +
  theme_minimal()
```

Looking at this chart, we can generally see that the average age of both the perps and victims is close, except for one outlier
in each of the Bronx, Brooklyn, Manhattan and Queens.

Another thing to notice from this sample, is that the majority of perps are males.

As for the race or ethnicity, no indication that this sample is leaning towards one specific race or ethnicity; we can see a fairly balanced distribution here.

Just to show the race related analysis in a dataframe, by counting the number pf perp_race in each borough:

```{r further analysis on race and ethnicity}
perp_race_stats_df <- perp_victim_stats_df %>%
  group_by(PERP_RACE) %>%
  count(PERP_RACE) %>%
  rename(count = n)
perp_race_stats_df
```

## Model

I will use a regression model to predict if the shooting is flagged as a murder or not.

Before doing that, I will wrangle the dataset and choose the feature(s).

The feature that I will use is the occurrence time; I want to compare the flag classification of incidents based on the time of the day.

```{r}
md_df <- original_df %>%
  separate(OCCUR_TIME, into = c("OCCUR_HOUR", "OCCUR_MIN", "OCCUR_SEC"), sep = "\\:") %>%
  select(-c("INCIDENT_KEY", "PRECINCT", "JURISDICTION_CODE", "LOC_CLASSFCTN_DESC", "LOCATION_DESC", "X_COORD_CD", "Y_COORD_CD", "Latitude", "Longitude", "Lon_Lat", "OCCUR_MIN", "OCCUR_SEC")) %>%
  na.omit() %>%
  filter(PERP_AGE_GROUP != "(null)" &
         PERP_SEX != "(null)" &
         PERP_RACE != "(null)" &
         VIC_RACE != "(null)") %>%
  relocate(STATISTICAL_MURDER_FLAG, .after = "VIC_RACE")
summary(md_df)
md_df
```

For the model I am going to use the following columns as features:

- BORO

- LOC_OF_OCCUR_DESC

- PERP_AGE_GROUP

- PERP_SEX

- PERP_RACE

- VIC_AGE_GROUP

- VIC_SEX

- VIC_RACE

```{r}
# Converting the feature columns to factors, in order to deal with the categorical variables by encoding them into dummy variables; factor takes care of this encoding:
md_df$BORO <- as.factor(md_df$BORO)
md_df$LOC_OF_OCCUR_DESC <- as.factor(md_df$LOC_OF_OCCUR_DESC)
md_df$PERP_AGE_GROUP <- as.factor(md_df$PERP_AGE_GROUP)
md_df$PERP_SEX <- as.factor(md_df$PERP_SEX)
md_df$PERP_RACE <- as.factor(md_df$PERP_RACE)
md_df$VIC_AGE_GROUP <- as.factor(md_df$VIC_AGE_GROUP)
md_df$VIC_SEX <- as.factor(md_df$VIC_SEX)
md_df$VIC_RACE <- as.factor(md_df$VIC_RACE)
md_df$STATISTICAL_MURDER_FLAG <- as.numeric(md_df$STATISTICAL_MURDER_FLAG)

# Building a regression model:
model <- glm(STATISTICAL_MURDER_FLAG ~ BORO + LOC_OF_OCCUR_DESC + PERP_AGE_GROUP + 
                PERP_SEX + PERP_RACE + VIC_AGE_GROUP + VIC_SEX + VIC_RACE + 
                OCCUR_HOUR, data = md_df, family = binomial)

# Showing the summary of the model:
summary(model)
```

- **Model Accuracy**:

```{r}
# Predicting the target classification values:
pred_target <- predict(model, md_df, type = "response")

# Converting the predicted classification values to binary classifications (threshold = 0.5)
pred_classification <- ifelse(pred_target > 0.5, 1, 0)

# Calculating the accuracy:
actual_classification <- md_df$STATISTICAL_MURDER_FLAG
accuracy <- mean(pred_classification == actual_classification)

# Printing the accuracy:
paste("Model Accuracy is:", round(accuracy*100, 2), "%")
```


Now, I am going to plot the comparison between the actual and predicted in order to visualize it and see clearly the differences throughout the hours of the day:

```{r building the required dataframe and visualize it}
# Creating the predicted classification dataframe:
pred_classification_df <- data.frame(pred_classification)

# # Creating the actual classification dataframe:
actual_classification_df <- data.frame(actual_classification)

# Combining the dataframes together into a single dataframe that will be used for plotting:
vis_df <- cbind(md_df$OCCUR_HOUR, actual_classification_df$actual_classification, pred_classification_df$pred_classification)
vis_df <- data.frame(vis_df)
vis_df_updated <- vis_df %>%
  rename("Occur_Hour" = X1, "Actual_Class" = X2, "Predicted_Class" = X3)

# Converting the data from wide to long format. The melt function reshapes the dataframe from wide to long format, separating Actual_Class and Predicted_Class into a single Class_Type column:
vis_df_updated_long <- melt(vis_df_updated, id.vars = "Occur_Hour", variable.name = "Class_Type", value.name = "Class")

# Plot using ggplot2
ggplot(vis_df_updated_long, aes(x = Occur_Hour, fill = Class)) +
  geom_bar(position = "dodge", stat = "count", aes(y = after_stat(count))) +
  facet_wrap(~Class_Type, scales = "free_y", ncol = 1) +
  labs(
    title = "Comparison of Actual vs Predicted Classes by Occur Hour",
    x = "Occur Hour",
    y = "Count",
    fill = "Class"
  ) +
  theme_minimal()
```

The model performs fairly with an accuracy of **76.93%**, however, it could be improved in many ways, such as:

- Increasing the data size for better training

- Trying different feature combinations

- Tweaking the model parameters

- Trying different regression models

- etc

We can also see clearly from the plot the difference in count for the classification between the predicted values and the actuals throughout the hours of the day.

The distribution of data in both the actual and predicted is similar, specifically for the non-murder flag.


## Conclusion and Summary

We can summarize our conclusion from this report as follows:

  - The shootings count has a parabolic trajectory, it peaks at midnight, goes gradually down where it reaches its minimum in the morning, and starts to rise also gradually until midnight.
  
  - The highest shooting count is in Brooklyn.
  
  - Majority of the perpetrators and victims were males.
  
  - The model to predict the shooting if it is a murder or not performed fairly with 76.93%, however, it could be improved using many techniques.
  
One can extract or aim to analyze many aspects in this dataset, as it contains rich information which can be interpreted in different ways.

What I have done here is purely based on personal analysis and simply curiosity.
